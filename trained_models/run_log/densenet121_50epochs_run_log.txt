Initializing to use pre-trained DenseNet 121 for feature extraction...
Params to learn:
	 classifier.weight
	 classifier.bias
Epoch 0/49
----------
train Loss: 0.7585 Acc: 0.5476
val Loss: 0.6052 Acc: 0.6739

Epoch 1/49
----------
train Loss: 0.7502 Acc: 0.5674
val Loss: 0.5739 Acc: 0.7064

Epoch 2/49
----------
train Loss: 0.7509 Acc: 0.5765
val Loss: 0.6161 Acc: 0.6600

Epoch 3/49
----------
train Loss: 0.7677 Acc: 0.5638
val Loss: 0.7626 Acc: 0.5702

Epoch 4/49
----------
train Loss: 0.7702 Acc: 0.5627
val Loss: 0.8039 Acc: 0.5607

Epoch 5/49
----------
train Loss: 0.7508 Acc: 0.5716
val Loss: 0.6994 Acc: 0.5803

Epoch 6/49
----------
train Loss: 0.7458 Acc: 0.5760
val Loss: 0.8628 Acc: 0.5336

Epoch 7/49
----------
train Loss: 0.7527 Acc: 0.5742
val Loss: 0.6421 Acc: 0.6376

Epoch 8/49
----------
train Loss: 0.7725 Acc: 0.5653
val Loss: 0.8850 Acc: 0.5271

Epoch 9/49
----------
train Loss: 0.7438 Acc: 0.5748
val Loss: 0.7241 Acc: 0.6051

Epoch 10/49
----------
train Loss: 0.7643 Acc: 0.5674
val Loss: 0.6911 Acc: 0.6112

Epoch 11/49
----------
train Loss: 0.7521 Acc: 0.5683
val Loss: 0.6420 Acc: 0.6403

Epoch 12/49
----------
train Loss: 0.7568 Acc: 0.5719
val Loss: 0.6286 Acc: 0.6498

Epoch 13/49
----------
train Loss: 0.7468 Acc: 0.5771
val Loss: 0.5833 Acc: 0.6929

Epoch 14/49
----------
train Loss: 0.7651 Acc: 0.5825
val Loss: 0.6158 Acc: 0.6702

Epoch 15/49
----------
train Loss: 0.7610 Acc: 0.5700
val Loss: 0.6279 Acc: 0.6502

Epoch 16/49
----------
train Loss: 0.7359 Acc: 0.5794
val Loss: 0.5939 Acc: 0.6912

Epoch 17/49
----------
train Loss: 0.7523 Acc: 0.5749
val Loss: 0.5959 Acc: 0.6834

Epoch 18/49
----------
train Loss: 0.7551 Acc: 0.5695
val Loss: 0.9181 Acc: 0.5183

Epoch 19/49
----------
train Loss: 0.7632 Acc: 0.5734
val Loss: 0.6793 Acc: 0.6176

Epoch 20/49
----------
train Loss: 0.7608 Acc: 0.5771
val Loss: 0.7158 Acc: 0.5817

Epoch 21/49
----------
train Loss: 0.7401 Acc: 0.5721
val Loss: 0.5903 Acc: 0.6895

Epoch 22/49
----------
train Loss: 0.7669 Acc: 0.5706
val Loss: 0.9714 Acc: 0.5085

Epoch 23/49
----------
train Loss: 0.7637 Acc: 0.5722
val Loss: 0.6684 Acc: 0.6241

Epoch 24/49
----------
train Loss: 0.7636 Acc: 0.5738
val Loss: 1.0887 Acc: 0.5024

Epoch 25/49
----------
train Loss: 0.7493 Acc: 0.5714
val Loss: 0.6115 Acc: 0.6753

Epoch 26/49
----------
train Loss: 0.7662 Acc: 0.5699
val Loss: 0.6829 Acc: 0.6119

Epoch 27/49
----------
train Loss: 0.7457 Acc: 0.5751
val Loss: 0.5632 Acc: 0.7163

Epoch 28/49
----------
train Loss: 0.7467 Acc: 0.5732
val Loss: 0.6466 Acc: 0.6383

Epoch 29/49
----------
train Loss: 0.7520 Acc: 0.5723
val Loss: 0.5891 Acc: 0.6851

Epoch 30/49
----------
train Loss: 0.7518 Acc: 0.5677
val Loss: 0.7408 Acc: 0.5644

Epoch 31/49
----------
train Loss: 0.7608 Acc: 0.5645
val Loss: 0.6012 Acc: 0.6793

Epoch 32/49
----------
train Loss: 0.7746 Acc: 0.5686
val Loss: 0.6828 Acc: 0.6193

Epoch 33/49
----------
train Loss: 0.7395 Acc: 0.5817
val Loss: 0.6966 Acc: 0.6153

Epoch 34/49
----------
train Loss: 0.7449 Acc: 0.5691
val Loss: 0.6214 Acc: 0.6593

Epoch 35/49
----------
train Loss: 0.7430 Acc: 0.5782
val Loss: 0.6421 Acc: 0.6356

Epoch 36/49
----------
val Loss: 0.6392 Acc: 0.6420

Epoch 37/49
----------
train Loss: 0.7422 Acc: 0.5780
val Loss: 0.6901 Acc: 0.6156

Epoch 38/49
----------
train Loss: 0.7635 Acc: 0.5682
val Loss: 0.8955 Acc: 0.5214

Epoch 39/49
----------
train Loss: 0.7499 Acc: 0.5749
val Loss: 0.5801 Acc: 0.7037

Epoch 40/49
----------
train Loss: 0.7371 Acc: 0.5758
val Loss: 0.6390 Acc: 0.6488

Epoch 41/49
----------
train Loss: 0.7503 Acc: 0.5743
val Loss: 0.6800 Acc: 0.6047

Epoch 42/49
----------
train Loss: 0.7536 Acc: 0.5726
val Loss: 0.5691 Acc: 0.7115

Epoch 43/49
----------
train Loss: 0.7528 Acc: 0.5718
val Loss: 0.5850 Acc: 0.6885

Epoch 44/49
----------
train Loss: 0.7558 Acc: 0.5742
val Loss: 0.6035 Acc: 0.6766

Epoch 45/49
----------
train Loss: 0.7488 Acc: 0.5754
val Loss: 0.9423 Acc: 0.5281

Epoch 46/49
----------
train Loss: 0.7666 Acc: 0.5682
val Loss: 0.6991 Acc: 0.6041

Epoch 47/49
----------
train Loss: 0.7634 Acc: 0.5717
val Loss: 0.6185 Acc: 0.6634

Epoch 48/49
----------
train Loss: 0.7610 Acc: 0.5650
val Loss: 0.6542 Acc: 0.6315

Epoch 49/49
----------
train Loss: 0.7634 Acc: 0.5721
val Loss: 0.6853 Acc: 0.6169

Training complete in 59m 32s
Best val Acc: 0.716271
Validation Accuracy History:
[tensor(0.6739, device='cuda:0', dtype=torch.float64), tensor(0.7064, device='cuda:0', dtype=torch.float64), tensor(0.6600, device='cuda:0', dtype=torch.float64), tensor(0.5702, device='cuda:0', dtype=torch.float64), tensor(0.5607, device='cuda:0', dtype=torch.float64), tensor(0.5803, device='cuda:0', dtype=torch.float64), tensor(0.5336, device='cuda:0', dtype=torch.float64), tensor(0.6376, device='cuda:0', dtype=torch.float64), tensor(0.5271, device='cuda:0', dtype=torch.float64), tensor(0.6051, device='cuda:0', dtype=torch.float64), tensor(0.6112, device='cuda:0', dtype=torch.float64), tensor(0.6403, device='cuda:0', dtype=torch.float64), tensor(0.6498, device='cuda:0', dtype=torch.float64), tensor(0.6929, device='cuda:0', dtype=torch.float64), tensor(0.6702, device='cuda:0', dtype=torch.float64), tensor(0.6502, device='cuda:0', dtype=torch.float64), tensor(0.6912, device='cuda:0', dtype=torch.float64), tensor(0.6834, device='cuda:0', dtype=torch.float64), tensor(0.5183, device='cuda:0', dtype=torch.float64), tensor(0.6176, device='cuda:0', dtype=torch.float64), tensor(0.5817, device='cuda:0', dtype=torch.float64), tensor(0.6895, device='cuda:0', dtype=torch.float64), tensor(0.5085, device='cuda:0', dtype=torch.float64), tensor(0.6241, device='cuda:0', dtype=torch.float64), tensor(0.5024, device='cuda:0', dtype=torch.float64), tensor(0.6753, device='cuda:0', dtype=torch.float64), tensor(0.6119, device='cuda:0', dtype=torch.float64), tensor(0.7163, device='cuda:0', dtype=torch.float64), tensor(0.6383, device='cuda:0', dtype=torch.float64), tensor(0.6851, device='cuda:0', dtype=torch.float64), tensor(0.5644, device='cuda:0', dtype=torch.float64), tensor(0.6793, device='cuda:0', dtype=torch.float64), tensor(0.6193, device='cuda:0', dtype=torch.float64), tensor(0.6153, device='cuda:0', dtype=torch.float64), tensor(0.6593, device='cuda:0', dtype=torch.float64), tensor(0.6356, device='cuda:0', dtype=torch.float64), tensor(0.6420, device='cuda:0', dtype=torch.float64), tensor(0.6156, device='cuda:0', dtype=torch.float64), tensor(0.5214, device='cuda:0', dtype=torch.float64), tensor(0.7037, device='cuda:0', dtype=torch.float64), tensor(0.6488, device='cuda:0', dtype=torch.float64), tensor(0.6047, device='cuda:0', dtype=torch.float64), tensor(0.7115, device='cuda:0', dtype=torch.float64), tensor(0.6885, device='cuda:0', dtype=torch.float64), tensor(0.6766, device='cuda:0', dtype=torch.float64), tensor(0.5281, device='cuda:0', dtype=torch.float64), tensor(0.6041, device='cuda:0', dtype=torch.float64), tensor(0.6634, device='cuda:0', dtype=torch.float64), tensor(0.6315, device='cuda:0', dtype=torch.float64), tensor(0.6169, device='cuda:0', dtype=torch.float64)]

Per epoch loss:
[0.758522340336891, 0.7501973130231734, 0.7508879506891254, 0.7677143352278991, 0.7702349130094868, 0.7507787384305682, 0.745844937621264, 0.7527260124240136, 0.7724820835296422, 0.7438285491004616, 0.764338105676692, 0.7520860955673188, 0.7567576338586975, 0.7467501343393046, 0.7651396505426754, 0.7610381553177731, 0.7359154252763364, 0.7523359004532054, 0.7550929111697202, 0.7631529046224754, 0.7607745967522526, 0.7400981888052536, 0.7669188211388784, 0.7636823988100787, 0.7635517724572796, 0.7492917523085488, 0.7662195200462864, 0.7456507213055038, 0.746740509913159, 0.7519855347538181, 0.7518058444329204, 0.7608116398118947, 0.7746316798185883, 0.7395349273896265, 0.7449067295414128, 0.7430177518486277, 0.7558775529889444, 0.7422376919305954, 0.7635458492532868, 0.7499250767608912, 0.7371366995794666, 0.7503467930506353, 0.7536052026347405, 0.7527716009397563, 0.755816909114442, 0.7488184140293099, 0.7666420559313899, 0.763400882867451, 0.7609543800680605, 0.7634432150333128]

Per epoch accuracy:
[tensor(0.5476, device='cuda:0', dtype=torch.float64), tensor(0.5674, device='cuda:0', dtype=torch.float64), tensor(0.5765, device='cuda:0', dtype=torch.float64), tensor(0.5638, device='cuda:0', dtype=torch.float64), tensor(0.5627, device='cuda:0', dtype=torch.float64), tensor(0.5716, device='cuda:0', dtype=torch.float64), tensor(0.5760, device='cuda:0', dtype=torch.float64), tensor(0.5742, device='cuda:0', dtype=torch.float64), tensor(0.5653, device='cuda:0', dtype=torch.float64), tensor(0.5748, device='cuda:0', dtype=torch.float64), tensor(0.5674, device='cuda:0', dtype=torch.float64), tensor(0.5683, device='cuda:0', dtype=torch.float64), tensor(0.5719, device='cuda:0', dtype=torch.float64), tensor(0.5771, device='cuda:0', dtype=torch.float64), tensor(0.5825, device='cuda:0', dtype=torch.float64), tensor(0.5700, device='cuda:0', dtype=torch.float64), tensor(0.5794, device='cuda:0', dtype=torch.float64), tensor(0.5749, device='cuda:0', dtype=torch.float64), tensor(0.5695, device='cuda:0', dtype=torch.float64), tensor(0.5734, device='cuda:0', dtype=torch.float64), tensor(0.5771, device='cuda:0', dtype=torch.float64), tensor(0.5721, device='cuda:0', dtype=torch.float64), tensor(0.5706, device='cuda:0', dtype=torch.float64), tensor(0.5722, device='cuda:0', dtype=torch.float64), tensor(0.5738, device='cuda:0', dtype=torch.float64), tensor(0.5714, device='cuda:0', dtype=torch.float64), tensor(0.5699, device='cuda:0', dtype=torch.float64), tensor(0.5751, device='cuda:0', dtype=torch.float64), tensor(0.5732, device='cuda:0', dtype=torch.float64), tensor(0.5723, device='cuda:0', dtype=torch.float64), tensor(0.5677, device='cuda:0', dtype=torch.float64), tensor(0.5645, device='cuda:0', dtype=torch.float64), tensor(0.5686, device='cuda:0', dtype=torch.float64), tensor(0.5817, device='cuda:0', dtype=torch.float64), tensor(0.5691, device='cuda:0', dtype=torch.float64), tensor(0.5782, device='cuda:0', dtype=torch.float64), tensor(0.5783, device='cuda:0', dtype=torch.float64), tensor(0.5780, device='cuda:0', dtype=torch.float64), tensor(0.5682, device='cuda:0', dtype=torch.float64), tensor(0.5749, device='cuda:0', dtype=torch.float64), tensor(0.5758, device='cuda:0', dtype=torch.float64), tensor(0.5743, device='cuda:0', dtype=torch.float64), tensor(0.5726, device='cuda:0', dtype=torch.float64), tensor(0.5718, device='cuda:0', dtype=torch.float64), tensor(0.5742, device='cuda:0', dtype=torch.float64), tensor(0.5754, device='cuda:0', dtype=torch.float64), tensor(0.5682, device='cuda:0', dtype=torch.float64), tensor(0.5717, device='cuda:0', dtype=torch.float64), tensor(0.5650, device='cuda:0', dtype=torch.float64), tensor(0.5721, device='cuda:0', dtype=torch.float64)]
Saving per_epoch_losses, per_epoch_accuracy to disk for analysis...
Saving final model to disk...
Running independent test...
Accuracy (Sklearn): 0.7053238385893523
F1-Score (Sklearn): 0.6964722319245545
Precision Score: 0.7050919377652051
Recall Score: 0.6880607315389924

Confusion Matrix:
[[1083  417]
 [ 452  997]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.72      0.71      1500
           1       0.71      0.69      0.70      1449

    accuracy                           0.71      2949
   macro avg       0.71      0.71      0.71      2949
weighted avg       0.71      0.71      0.71      2949



Accuracy of the network on the test images: 70 %