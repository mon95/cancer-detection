{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of ChestX-14 data and Convert to PyTorch ImageFolder directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For this to work, you would need to run this script after downloading & extracting the CheXpert-v1.0-small dataset. Ideally, there's no need to run this anymore - but if we need additional data for some reason (or to run new experiments), it might be easy to start with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chest_xray_df = pd.read_csv('CheXpert-v1.0-small/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CancerDetected: 9186\n",
      "       Unreliable/Unsure(labelled 0): 1270\n",
      "       No Cancer(labelled -1): 1488\n"
     ]
    }
   ],
   "source": [
    "print(f\"CancerDetected: {(chest_xray_df['Lung Lesion'] == 1).sum()}\\n \\\n",
    "      Unreliable/Unsure(labelled 0): {(chest_xray_df['Lung Lesion'] == 0).sum()}\\n \\\n",
    "      No Cancer(labelled -1): {(chest_xray_df['Lung Lesion'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move positive training instance images to train/malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patient00019_study3_view1_frontal.jpg'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_images = chest_xray_df[chest_xray_df['Lung Lesion'] == 1]\n",
    "cancer_images = cancer_images[['Path', 'Lung Lesion']]\n",
    "image_path = cancer_images.iloc[i]['Path'].split('/')\n",
    "\n",
    "'_'.join([x for x in image_path[-3:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_root_dir = 'data/train/malignant/'\n",
    "\n",
    "for i in range(len(cancer_images)):\n",
    "    image_path = cancer_images.iloc[i]['Path'].split('/')\n",
    "    new_image_name = new_image_root_dir + '_'.join([x for x in image_path[-3:]])\n",
    "    \n",
    "    im = io.imread(cancer_images.iloc[i]['Path'])\n",
    "    io.imsave(new_image_name, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move negative training instance images to train/benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_cancer_images = chest_xray_df[chest_xray_df['Lung Lesion'] == -1]\n",
    "no_cancer_images = no_cancer_images[['Path', 'Lung Lesion']]\n",
    "len(no_cancer_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_root_dir = 'data/train/benign/'\n",
    "\n",
    "for i in range(len(no_cancer_images)):\n",
    "    image_path = no_cancer_images.iloc[i]['Path'].split('/')\n",
    "    new_image_name = new_image_root_dir + '_'.join([x for x in image_path[-3:]])\n",
    "    \n",
    "    im = io.imread(no_cancer_images.iloc[i]['Path'])\n",
    "    io.imsave(new_image_name, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move \"No finding\" instances to train/benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoFindings: 22381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chest_xray_df = pd.read_csv('CheXpert-v1.0-small/train.csv')\n",
    "print(f\"NoFindings: {(chest_xray_df['No Finding'] == 1).sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22381"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get df \n",
    "no_findings_df = chest_xray_df[chest_xray_df['No Finding'] == 1]\n",
    "no_findings_df = no_findings_df[['Path']]\n",
    "len(no_findings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_image_in_specific_row_to_folder(no_findings_df, i, image_root_dir):\n",
    "    image_path = no_findings_df.iloc[i]['Path'].split('/')\n",
    "    new_image_name = image_root_dir + '_'.join([x for x in image_path[-3:]])\n",
    "    \n",
    "    im = io.imread(no_findings_df.iloc[i]['Path'])\n",
    "    io.imsave(new_image_name, im)\n",
    "    \n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "image_root_dir = 'data/train/benign/'\n",
    "while i < 5000:\n",
    "    # Move to train/benign\n",
    "    move_image_in_specific_row_to_folder(no_findings_df, i, image_root_dir)\n",
    "    i += 1\n",
    "    \n",
    "image_root_dir = 'data/val/benign/'\n",
    "while i <6500:\n",
    "    # Move to val/benign\n",
    "    move_image_in_specific_row_to_folder(no_findings_df, i, image_root_dir)\n",
    "    i += 1\n",
    "    \n",
    "image_root_dir = 'data/test/benign/'\n",
    "while i < 8000:\n",
    "    # Move to test/benign\n",
    "    move_image_in_specific_row_to_folder(no_findings_df, i, image_root_dir)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for images in original val folder (Note: Using this as our independent test folder as we have no access to the hosted independed test folder on the website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CancerDetected: 1\n",
      "       Unreliable/Unsure(labelled 0): 233\n",
      "       No Cancer(labelled -1): 0\n"
     ]
    }
   ],
   "source": [
    "chest_xray_df = pd.read_csv('CheXpert-v1.0-small/valid.csv')\n",
    "print(f\"CancerDetected: {(chest_xray_df['Lung Lesion'] == 1).sum()}\\n \\\n",
    "      Unreliable/Unsure(labelled 0): {(chest_xray_df['Lung Lesion'] == 0).sum()}\\n \\\n",
    "      No Cancer(labelled -1): {(chest_xray_df['Lung Lesion'] == -1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "\n",
    "Sree:\n",
    "Looks like there's just one positive image here. My initial plan was to use all +ve and -ve from here as our independent test set. But now we'll have to choose from one of these two options:\n",
    "1. Split the data in train into test and val (that has ~9k cancer images. So we're looking at 6k,1.5k, 1.5k ish - which might work alright.\n",
    "2. We switch to using the larger dataset :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial on writing a custom dataset - (Ignore) (I decided it was easier to use ImageFolder from pytorch as we already have scripts that train using this; So the script above does the conversion of our data to the expected format for ImageFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "\n",
    "# Interactive mode\n",
    "plt.ion()\n",
    "\n",
    "### Tutorial - Writing custom Dataset \n",
    "\n",
    "# Constants\n",
    "faces_dir = 'faces/'\n",
    "\n",
    "def show_landmarks(image, landmarks):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "landmarks_df = pd.read_csv('faces/face_landmarks.csv')\n",
    "landmarks_df.head(3)\n",
    "image_names = landmarks_df['image_name']\n",
    "landmarks = landmarks_df.iloc[:, 1:].as_matrix()\n",
    "landmarks = landmarks.reshape(-1, 2)\n",
    "print(landmarks.shape)\n",
    "show_landmarks(plt.imread(faces_dir + image_names.iloc[0]), landmarks[:68]) # 68 feats per image\n",
    "\n",
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Face Landmarks Dataset. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): path to csv file containing annotations\n",
    "            root_dir (string): root directory containing all images\n",
    "            transform (callable, optional): Optional transform to be applied on sample\n",
    "        \"\"\"\n",
    "        self.landmarks_df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        # return the size of your dataset\n",
    "        return len(self.landmarks_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # dataset[i] -> returns ith sample\n",
    "        if torch.is_tensor(idx): \n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_df.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        landmarks = self.landmarks_df.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "face_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv', root_dir='faces/')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(face_dataset)):\n",
    "    sample = face_dataset[i]    \n",
    "    print(i, sample['image'].shape, sample['landmarks'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i+1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ax.set_title(f'Sample {i}:')\n",
    "    ax.axis('off')\n",
    "#     print(**sample)\n",
    "    show_landmarks(**sample)\n",
    "    \n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"\n",
    "    Rescale the image in a sample to a given size\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'landmarks': landmarks}\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
